{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Modules\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Modules Related to PDF Pre-Processing\n",
    "#import fitz\n",
    "import os\n",
    "#import pdfplumber\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "#from fpdf import FPDF\n",
    "import PIL.Image\n",
    "\n",
    "# Modules Related to PDF Processing\n",
    "#from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chains import RetrievalQA,StuffDocumentsChain ,LLMChain\n",
    "\n",
    "# Modules Related to SQL Processing \n",
    "import psycopg2\n",
    "import urllib\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "from langchain.agents import create_sql_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import UnstructuredExcelLoader\n",
    "\n",
    "\n",
    "import google.generativeai as genai\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.Gemini API Key\n",
    "GOOGLE_API_KEY = 'AIzaSyBIBaI7Cr-bINi-cRK9BHa2rUMK2MpqONQ'\n",
    "model = GoogleGenerativeAI(model=\"gemini-pro\", temperature=0.3, google_api_key=GOOGLE_API_KEY)\n",
    "chat_model = ChatGoogleGenerativeAI(model=\"gemini-pro\",google_api_key=GOOGLE_API_KEY,)\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\",google_api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql_query_from_excel(file1_name,query): \n",
    "# def get_sql_query_from_excel(query):  \n",
    "\n",
    "    print(\"file1_name in get_sql_query_from_excel--->\",file1_name)\n",
    "\n",
    "#    path=os.getcwd()\n",
    "#    file_name=\"test_mgu22_copy.xlsx\"\n",
    "#    file_path=os.path.join(path,file_name)\n",
    "\n",
    "#     loaders = [UnstructuredExcelLoader(r\"C:\\Users\\40019115\\BMW\\03-04-2024\\Logs.xlsx\")]\n",
    "#     loaders = [UnstructuredExcelLoader(\"test_mgu22_copy.xlsx\")]\n",
    "    loaders = [UnstructuredExcelLoader(file1_name)]\n",
    "\n",
    "    docs = []\n",
    "    for loader in loaders:\n",
    "        docs.extend(loader.load())\n",
    "#    print(docs)\n",
    "    vectorstore_db = FAISS.from_documents(docs,embeddings)\n",
    "    embeddings_vector = embeddings.embed_query(query)\n",
    "    docs = vectorstore_db.similarity_search_by_vector(embeddings_vector)\n",
    "    prompt_template = \"\"\"\n",
    "    You are the best in reading the excel sheet and summarize the logs.\n",
    "    if the question is related to xbl - search the excel for keywords like \"xbl_ram_dump\" and output the entire row\n",
    "    if the question is related to service failure - search the keywords 'service failure'\n",
    "    if there is no answers in the context just give response \"please refer the logs\"\\n\\n\n",
    " \n",
    "   \n",
    "    Context:\\n {context}?\\n\n",
    "    Question: \\n{question}\\n\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "    context = docs\n",
    "#    print(context)\n",
    "    prompt = PromptTemplate(template = prompt_template, input_variables = [\"context\", \"question\"])\n",
    "    qa_retreival = LLMChain(llm=chat_model,prompt=prompt,return_final_only=True)\n",
    "    response = qa_retreival.invoke({\"context\": context, \"question\": query})\n",
    "    response = response[\"text\"]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"Search for xbl? Show the entire row\"\n",
    "# get_sql_query_from_excel(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_agent(query):\n",
    "    prompt = (\n",
    "        \"\"\"\n",
    "            if the query contains the word \"DESCRIPTION\" or \"desc\"\n",
    "            for example: what is the description of id = 647? or \"what is id=647\"\n",
    "            return 'description'; \n",
    "            else:\n",
    "            return 'status'. \n",
    "            Below is the query.\n",
    "            Query: \n",
    "            \"\"\" +\n",
    "       \n",
    "         query\n",
    "    )\n",
    "    # model = GoogleGenerativeAI(model=\"gemini-pro\", temperature=0.3, google_api_key=GOOGLE_API_KEY)\n",
    "    response = model.invoke(prompt)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_description(file_name2,query):\n",
    "def get_description(query):\n",
    "\n",
    "#     print(\"File2--->\",file_name2)\n",
    "    loaders = [UnstructuredExcelLoader(\"Combined.xlsx\")]\n",
    "    docs = []\n",
    "    for loader in loaders:\n",
    "        docs.extend(loader.load())\n",
    "    vectorstore_db = FAISS.from_documents(docs,embeddings)\n",
    "    embeddings_vector = embeddings.embed_query(query)\n",
    "    docs = vectorstore_db.similarity_search_by_vector(embeddings_vector)\n",
    "    prompt_template = \"\"\"\n",
    "    You are the best in reading the excel sheet give descriptions of sink ids and source ids.\n",
    "    if there is no answers in the context just reply \"Answer is not available in the provided context\"\\n\\n\n",
    "\n",
    "    \n",
    "    Context:\\n {context}?\\n\n",
    "    Question: \\n{question}\\n \n",
    "    Answer: \n",
    "    \"\"\"\n",
    "    context = docs[:2]\n",
    "    prompt = PromptTemplate(template = prompt_template, input_variables = [\"context\", \"question\"])\n",
    "    qa_retreival = LLMChain(llm=chat_model,prompt=prompt)\n",
    "    response = qa_retreival.invoke({\"context\": context, \"question\": query})\n",
    "    response = response[\"text\"]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # query = \"summarize the sink and souce ids available in the data along with their connection status in a list ?\"\n",
    "# # query = \"list the connection details of sink id 1024?\"\n",
    "# # query = \"summarize the sink and souce ids along with their connection status in a list ?\"\n",
    "# # query = \"summarize the sink and souce ids with their unavailable status in a list ?\"\n",
    "# # query = \"summarize the logs?\"\n",
    "# # query = \"details of sink and souce ids which are not in connected state?\"\n",
    "# # query = \"maximum and minimum connection ids of sink id 646?\"\n",
    "# # query = \"count of connection ids of sink id 1024?\"\n",
    "# # query = \"what is the description of id = 129? \"\n",
    "# # query = \"connections of all the source and sink ids along with connectionID? \"\n",
    "# # query = \"count of unavailable connection IDs made to each source and sink id?\"\n",
    "# # query = \" for the unavailable sink IDs what is the count of connection ID ?\"\n",
    "# # query = \" What is the connection status along with source and sink ids for the different connetions?\"\n",
    "# # query = \" what is the connection status along with source and sink ids?\"\n",
    "# # query = \"list all the connection IDs \"\n",
    "# # query = \"What sources and sink ids are unavailable?\"\n",
    "# # query = \"What are the lastheardsourceandsinkids?\"\n",
    "# # query = \"What are sources and sinks which are unavailable for Connection ID 118?\"\n",
    "# # query = \"What is the maximum and minimum connection ids for source ID 1024?\"\n",
    "# query = \"What sources and sink ids are connected?\"\n",
    "\n",
    "\n",
    "# question_source = query_agent(query) \n",
    "# pattern ='status'\n",
    "# match = re.search(pattern, str(question_source), re.IGNORECASE)\n",
    "# if match:\n",
    "#     print(get_sql_query_from_excel(query))\n",
    "    \n",
    "# else:\n",
    "#     print(get_description(query))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the provided context, there are some instances where sources and sink ids are reported as not available. These instances are indicated by the keywords 'not avail', 'isSinkAvailable', and 'isSourceAvailable'. The following source and sink ids are reported as unavailable:\n",
    "# - MainConn ID=72::isSinkAvailable(): Sink 1024 not avail\n",
    "# - SM MainConn ID=72::isSinkAvailable(): Sink 1024 not avail\n",
    "# - SM MainConn ID=73::isSinkAvailable(): Sink 1024 not avail\n",
    "# - SM MainConn ID=118::isSourceAvailable(): src 644 not avail\n",
    "# - SM MainConn ID=118::isSourceAvailable(): src 647 not avail\n",
    "# - SM MainConn ID=118::isSourceAvailable(): src 646 not avail\n",
    "\n",
    "# Therefore, the unavailable source ids are 644, 647, and 646, and the unavailable sink ids are 1024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from flask import Flask, request, jsonify\n",
    "# from flask_cors import CORS\n",
    "# import warnings\n",
    "# app = Flask(__name__)\n",
    "# CORS(app)\n",
    "# @app.route('/receive_data_final_final2', methods=['POST'])\n",
    "# def receive_data():\n",
    "#     try:\n",
    "#         if request.method == 'POST':\n",
    "#             received_data = request.json  # Get the JSON data sent from frontend\n",
    "#             print(\"received_data----->\", received_data)\n",
    "            \n",
    "#             # Print received data for testing purposes\n",
    "# #             print(\"received_data sample\", received_data[\"messages\"])  # Print received data for testing purposes\n",
    "# #             user_input = [data['content'] for data in received_data[\"messages\"] if data.get('role') == 'user']\n",
    "            \n",
    "#             print(\"received_data sample\", received_data[\"message\"])  # Print received data for testing purposes\n",
    "# #             user_input = [data['content'] for data in received_data[\"message\"] if data.get('role') == 'user']\n",
    "# #             print(\"user input----->\", user_input)\n",
    "        \n",
    "#             user_question = received_data[\"message\"]\n",
    "#             print(\"user question\",user_question)\n",
    "\n",
    "#             question_source = query_agent(user_question)\n",
    "#             pattern = 'status'\n",
    "#             match = re.search(pattern, str(question_source), re.IGNORECASE)\n",
    "#             if match:\n",
    "                \n",
    "#                 agent_output=get_sql_query_from_excel(user_question)\n",
    "#                 print(\"output--->\",agent_output)\n",
    "#                 received_data.update({'role': 'assistant', 'content': agent_output})\n",
    "#             else:\n",
    "#                 print(\"nothing\")\n",
    "#                 result=get_description(user_question)\n",
    "        \n",
    "#                 print(\"final result->\",result)\n",
    "    \n",
    "\n",
    "#                 received_data.update({'role': 'assistant', 'content2': result,'error':\"error\"})\n",
    "#             return jsonify(received_data)\n",
    "\n",
    "\n",
    " \n",
    "#     except Exception as e:\n",
    "#         print(\"Error:\", e)\n",
    "#         print(\"received_data final ----->\", received_data)\n",
    "#         return jsonify({\"message\": \"Error processing data\"}), 500\n",
    " \n",
    " \n",
    "# if __name__ == '__main__':\n",
    "#     app.run(host='127.0.0.1', port=9008, debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:9008\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [21/Sep/2024 17:25:08] \"OPTIONS /receive_data_final_final2 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "received_data-----> {'message': 'Search for xbl? Show the entire row'}\n",
      "received_data-----> {'message': 'Search for xbl? Show the entire row'}\n",
      "received_data sample Search for xbl? Show the entire row\n",
      "user question Search for xbl? Show the entire row\n",
      "log_file-------> None\n",
      "file1_name in get_sql_query_from_excel---> None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2024 17:25:18] \"POST /receive_data_final_final2 HTTP/1.1\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Either 'filename' or 'file' argument must be specified\n",
      "received_data final2 -----> {'message': 'Search for xbl? Show the entire row'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2024 17:32:27] \"OPTIONS /receive_data_final_final2 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "received_data-----> {'message': 'Search for xbl? Show the entire row'}\n",
      "received_data-----> {'message': 'Search for xbl? Show the entire row'}\n",
      "received_data sample Search for xbl? Show the entire row\n",
      "user question Search for xbl? Show the entire row\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2024 17:32:29] \"POST /receive_data_final_final2 HTTP/1.1\" 500 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_file-------> None\n",
      "file1_name in get_sql_query_from_excel---> None\n",
      "Error: Either 'filename' or 'file' argument must be specified\n",
      "received_data final2 -----> {'message': 'Search for xbl? Show the entire row'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2024 17:37:40] \"OPTIONS /receive_data_final_final2 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2024 17:37:40] \"POST /receive_data_final_final2 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "received_data-----> {'files': ['test_mgu22_copy.xlsx']}\n",
      "Received file names: ['test_mgu22_copy.xlsx']\n",
      "file1_namefile2_name--------> test_mgu22_copy.xlsx None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2024 17:38:00] \"OPTIONS /receive_data_final_final2 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "received_data-----> {'message': '<pre style=\"font-family: monospace; font-size: 14px; padding: 1px 0px; margin-bottom: 0px; line-height: inherit; color: rgb(0, 0, 0); word-break: break-all; overflow-wrap: break-word; background-color: rgb(255, 255, 255); border: 0px; border-radius: 0px; text-wrap: wrap; vertical-align: baseline;\">Search for xbl? Show the entire row</pre>'}\n",
      "received_data-----> {'message': '<pre style=\"font-family: monospace; font-size: 14px; padding: 1px 0px; margin-bottom: 0px; line-height: inherit; color: rgb(0, 0, 0); word-break: break-all; overflow-wrap: break-word; background-color: rgb(255, 255, 255); border: 0px; border-radius: 0px; text-wrap: wrap; vertical-align: baseline;\">Search for xbl? Show the entire row</pre>'}\n",
      "received_data sample <pre style=\"font-family: monospace; font-size: 14px; padding: 1px 0px; margin-bottom: 0px; line-height: inherit; color: rgb(0, 0, 0); word-break: break-all; overflow-wrap: break-word; background-color: rgb(255, 255, 255); border: 0px; border-radius: 0px; text-wrap: wrap; vertical-align: baseline;\">Search for xbl? Show the entire row</pre>\n",
      "user question <pre style=\"font-family: monospace; font-size: 14px; padding: 1px 0px; margin-bottom: 0px; line-height: inherit; color: rgb(0, 0, 0); word-break: break-all; overflow-wrap: break-word; background-color: rgb(255, 255, 255); border: 0px; border-radius: 0px; text-wrap: wrap; vertical-align: baseline;\">Search for xbl? Show the entire row</pre>\n",
      "log_file-------> test_mgu22_copy.xlsx\n",
      "file1_name in get_sql_query_from_excel---> test_mgu22_copy.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\40019115\\AppData\\Roaming\\Python\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n",
      "127.0.0.1 - - [21/Sep/2024 17:38:13] \"POST /receive_data_final_final2 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output---> | timestamp | level | service | log |\n",
      "| --------- | ----- | ------- | --- |\n",
      "| 2024-07-04 23:01:13,583 | DEBUG | mtee.testing.xunit_plugin | Recording for test case: <function test_serial_marker_xbl_ram_dump at 0x7f16bbb024d0> |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2024 17:38:50] \"OPTIONS /receive_data_final_final2 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [21/Sep/2024 17:38:50] \"POST /receive_data_final_final2 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "received_data-----> {'files': ['test_mgu22_copy.xlsx']}\n",
      "Received file names: ['test_mgu22_copy.xlsx']\n",
      "file1_namefile2_name--------> test_mgu22_copy.xlsx None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2024 17:38:55] \"OPTIONS /receive_data_final_final2 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "received_data-----> {'message': '<pre style=\"font-family: monospace; font-size: 14px; padding: 1px 0px; margin-bottom: 0px; line-height: inherit; color: rgb(0, 0, 0); word-break: break-all; overflow-wrap: break-word; background-color: rgb(255, 255, 255); border: 0px; border-radius: 0px; text-wrap: wrap; vertical-align: baseline;\">Search for xbl? Show the entire row</pre>'}\n",
      "received_data-----> {'message': '<pre style=\"font-family: monospace; font-size: 14px; padding: 1px 0px; margin-bottom: 0px; line-height: inherit; color: rgb(0, 0, 0); word-break: break-all; overflow-wrap: break-word; background-color: rgb(255, 255, 255); border: 0px; border-radius: 0px; text-wrap: wrap; vertical-align: baseline;\">Search for xbl? Show the entire row</pre>'}\n",
      "received_data sample <pre style=\"font-family: monospace; font-size: 14px; padding: 1px 0px; margin-bottom: 0px; line-height: inherit; color: rgb(0, 0, 0); word-break: break-all; overflow-wrap: break-word; background-color: rgb(255, 255, 255); border: 0px; border-radius: 0px; text-wrap: wrap; vertical-align: baseline;\">Search for xbl? Show the entire row</pre>\n",
      "user question <pre style=\"font-family: monospace; font-size: 14px; padding: 1px 0px; margin-bottom: 0px; line-height: inherit; color: rgb(0, 0, 0); word-break: break-all; overflow-wrap: break-word; background-color: rgb(255, 255, 255); border: 0px; border-radius: 0px; text-wrap: wrap; vertical-align: baseline;\">Search for xbl? Show the entire row</pre>\n",
      "log_file-------> test_mgu22_copy.xlsx\n",
      "file1_name in get_sql_query_from_excel---> test_mgu22_copy.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [21/Sep/2024 17:39:00] \"POST /receive_data_final_final2 HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output---> | logtime | level | context | details |\n",
      "|---|---|---|---|\n",
      "| 2024-07-04 23:01:13,583 | DEBUG | [mtee.testing.xunit_plugin] | Recording for test case: <function test_serial_marker_xbl_ram_dump at 0x7f16bbb024d0> |\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "import warnings\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "file1_name=None\n",
    "file2_name=None\n",
    "\n",
    "@app.route('/receive_data_final_final2', methods=['POST'])\n",
    "def receive_data():\n",
    "    global file1_name,file2_name\n",
    "    try:\n",
    "        if request.method == 'POST':\n",
    "\n",
    "            received_data = request.json  # Get the JSON data sent from frontend\n",
    "            print(\"received_data----->\", received_data)\n",
    "            \n",
    "            if \"files\" in received_data:\n",
    "                \n",
    "                file_names = received_data.get('files', [])\n",
    "                print(\"Received file names:\", file_names)\n",
    "                \n",
    "                file1_name=file_names[0]\n",
    "                \n",
    "#                 file1_name=[files for files in file_names if files.startswith(\"Log\")][0]\n",
    "#                 file2_name= [files for files in file_names if not files.startswith(\"Log\")][0]\n",
    "                \n",
    "                print(\"file1_namefile2_name-------->\",file1_name,file2_name)\n",
    "                \n",
    "                return jsonify({\"message\": \"File names received successfully\", \"file_names\": file_names}), 200\n",
    "\n",
    "                \n",
    "            if \"message\" in received_data:\n",
    "                \n",
    "            \n",
    "                print(\"received_data----->\", received_data)\n",
    "                print(\"received_data sample\", received_data[\"message\"])  # Print received data for testing purposes\n",
    "\n",
    "                user_question = received_data[\"message\"]\n",
    "                print(\"user question\",user_question)\n",
    "\n",
    "                question_source = query_agent(user_question)\n",
    "                pattern = 'status'\n",
    "                match = re.search(pattern, str(question_source), re.IGNORECASE)\n",
    "                if match:\n",
    "                    log_file=file1_name\n",
    "                    print(\"log_file------->\",log_file)\n",
    "#                     agent_output=get_sql_query_from_excel(user_question)\n",
    "\n",
    "                    agent_output=get_sql_query_from_excel(file1_name,user_question)\n",
    "                    print(\"output--->\",agent_output)\n",
    "                    received_data.update({'role': 'assistant', 'content': agent_output})\n",
    "                else:\n",
    "                    print(\"Description----->\")\n",
    "                    description_file=file2_name\n",
    "                    print(\"description_file------->\",file2_name)\n",
    "                    result=get_description(user_question)\n",
    "\n",
    "#                     result=get_description(file2_name,user_question)\n",
    "                    print(\"final result->\",result)\n",
    "\n",
    "\n",
    "                    received_data.update({'role': 'assistant', 'content2': result,'error':\"error\"})\n",
    "                return jsonify(received_data)\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "            print(\"received_data final2 ----->\", received_data)\n",
    "            return jsonify({\"message\": \"Error processing data\"}), 500\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    app.run(host='127.0.0.1', port=9008, debug=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
